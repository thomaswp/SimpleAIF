{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf796019",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assignmentID = 100\n",
    "assignmentID = 139\n",
    "\n",
    "query = f\"\"\"\n",
    "select SubjectID, AssignmentID, CodeStateID, InterventionType, InterventionMessage, Score, Contents from (\n",
    "select SubjectID, AssignmentID, CodeStateID, InterventionType, InterventionMessage, Score, CodeStateSection from MainTable where AssignmentId = \"{assignmentID}\" and InterventionCategory = \"Feedback\"\n",
    ") as main JOIN CodeState where main.CodeStateID = CodeState.ID and main.CodeStateSection = CodeState.Filename\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"data/progsnap2_21_consenting_no_demographics.db\")\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "df[\"Correct\"] = df.InterventionType == \"complete|Complete\"\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df.Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a Score column, but the problem is it's usually only the final submitted code\n",
    "# after students have gotten lots of automated feedback from the system.\n",
    "# The above method is less PS2-y but gives us more midway attempts that are incorrect.\n",
    "# Not necessarily an issue, since Snap has the same issue and works mostly fine. \n",
    "df.Score.astype(float, errors='ignore').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f632ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, token, tokenize, io\n",
    "\n",
    "# Credit: https://gist.github.com/BroHui/aca2b8e6e6bdf3cb4af4b246c9837fa3\n",
    "def strip_comments(source):\n",
    "    \n",
    "    if (source is None or len(source.strip()) == 0):\n",
    "        return \"\"\n",
    "\n",
    "    prev_toktype = token.INDENT\n",
    "    first_line = None\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "\n",
    "    mod = \"\"\n",
    "    \n",
    "    tokgen = tokenize.generate_tokens(io.StringIO(source).readline)\n",
    "    try:\n",
    "        for toktype, ttext, (slineno, scol), (elineno, ecol), ltext in tokgen:\n",
    "            if 0:   # Change to if 1 to see the tokens fly by.\n",
    "                print(\"%10s %-14s %-20r %r\" % (\n",
    "                    tokenize.tok_name.get(toktype, toktype),\n",
    "                    \"%d.%d-%d.%d\" % (slineno, scol, elineno, ecol),\n",
    "                    ttext, ltext\n",
    "                    ))\n",
    "            if slineno > last_lineno:\n",
    "                last_col = 0\n",
    "            if scol > last_col:\n",
    "                mod += (\" \" * (scol - last_col))\n",
    "            if toktype == token.STRING and (prev_toktype == token.INDENT or prev_toktype == token.NEWLINE):\n",
    "                # Docstring\n",
    "                mod += (\"#--\")\n",
    "            elif toktype == tokenize.COMMENT:\n",
    "                # Comment\n",
    "                mod += (\"##\\n\")\n",
    "            else:\n",
    "                mod += (ttext)\n",
    "            prev_toktype = toktype\n",
    "            last_col = ecol\n",
    "            last_lineno = elineno\n",
    "    except:\n",
    "        # Parse failure ==> Return original\n",
    "        return source\n",
    "    \n",
    "    return mod\n",
    "        \n",
    "print(strip_comments(df.Contents[0].decode('UTF-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Code\"] = df.Contents.str.decode('UTF-8').apply(strip_comments)\n",
    "print(df.Code[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa27c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "X = df.Code\n",
    "y = df.Correct\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_code, X_test_code, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#vectorizer = TfidfVectorizer(lowercase=False, token_pattern=\"[\\w]+|[^\\s]|[ ]{4}\")\n",
    "vectorizer = CountVectorizer(lowercase=False, token_pattern=\"[\\w]+|[^\\s]|[ ]{4}\", ngram_range=(1,3))\n",
    "vectorizer.fit(X_train_code)\n",
    "X_train = vectorizer.transform(X_train_code)\n",
    "X_test = vectorizer.transform(X_test_code)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "np.mean(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baebeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier, cv\n",
    "\n",
    "# clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                        # n_estimators=20, random_state=0).fit(X_resampled, y_resampled)\n",
    "\n",
    "# clf = SVC().fit(X_resampled, y_resampled)\n",
    "\n",
    "clf = XGBClassifier().fit(X_resampled, y_resampled)\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('scale', StandardScaler(with_mean=False)),\n",
    "#     ('logistic', LogisticRegressionCV(cv=5, random_state=1234, max_iter=1000))\n",
    "# ]).fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Training performance (without oversampling)\n",
    "pred_train = clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "confusion_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201b0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd637aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', clf)])\n",
    "\n",
    "with open(f'../server/data/BlockPy/model-{assignmentID}.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_code[y_train].reset_index().Code.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c005cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_odd(a_number: int) -> bool:\n",
    "    #--\n",
    "    return a_number % 2 == 1\n",
    "\n",
    "def maximum_odd(odd: list) -> int:\n",
    "    max = odd[0]\n",
    "    for num in odd:\n",
    "        if is_odd(num):\n",
    "            if num > max:\n",
    "                max = num\n",
    "    return max\n",
    "\n",
    "maximum_odd([1, 2, 7, 8, 9, 3, 4, 5, 6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"def is_odd(a_number: int) -> bool:\n",
    "    #--\n",
    "    return a_number % 2 == 1\n",
    "assert_equal(is_odd(31), True)\n",
    "assert_equal(is_odd(22), False)\n",
    "assert_equal(is_odd(4312), False)\n",
    "\n",
    "def maximum_odd(numbers: [int]) -> int: \n",
    "    max_odd = 0\n",
    "    for number in numbers: \n",
    "        if number > max_odd and is_odd(number): \n",
    "            max_odd = number\n",
    "    return max_odd\n",
    "assert_equal(maximum_odd([2, 3, 1, 43, 1, 0]), 43)\n",
    "assert_equal(maximum_odd([3, 3, 1, 46, 90, 0]), 3)\n",
    "assert_equal(maximum_odd([2, 18, 90, 2, 40, 67]), 67)\n",
    "\"\"\"\n",
    "\n",
    "pipe.predict_proba([code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# probs = np.mean(np.array([est.predict_proba(X_test)[:,1] for est in clf.estimators_]), axis = 0)\n",
    "# sns.histplot(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe70bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unweighted_prediction(clf, X):\n",
    "    preds = np.array([est.predict(X) for est in clf.estimators_])\n",
    "    probs = np.mean(preds, axis = 0)\n",
    "    pmax = np.max(probs)\n",
    "    pmin = np.min(probs)\n",
    "    return (probs - pmin) / (pmax - pmin)\n",
    "\n",
    "# sns.histplot(unweighted_prediction(clf, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e046ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot((X_train[y_train].toarray() > 0).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../server')\n",
    "\n",
    "import progress\n",
    "\n",
    "estimator = progress.ProgressEstimator().fit(X_train[y_train])\n",
    "\n",
    "sns.histplot(estimator.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9032893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', estimator)])\n",
    "\n",
    "with open(f'../server/data/BlockPy/progress-{assignmentID}.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "select SubjectID, AssignmentID, CodeStateID, Contents from (\n",
    "select SubjectID, AssignmentID, CodeStateID, CodeStateSection from MainTable where AssignmentId = \"{assignmentID}\" and EventType=\"File.Edit\"\n",
    ") as main JOIN CodeState where main.CodeStateID = CodeState.ID and main.CodeStateSection = CodeState.Filename\n",
    "\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"data/progsnap2_21_consenting_no_demographics.db\")\n",
    "all_edits = pd.read_sql_query(query, con)\n",
    "\n",
    "all_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_edits_code = all_edits.Contents.str.decode('UTF-8').apply(strip_comments)\n",
    "X_edits = vectorizer.transform(X_edits_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0643d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87372e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.min_score)\n",
    "print(estimator.max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(estimator.predict_proba(X_edits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da51ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({\n",
    "    'Code': X_test_code,\n",
    "    'Progress_score': progress_score(X_test),\n",
    "    'Correctness_score': clf.predict_proba(X_test)[:,1],\n",
    "    'Correct': y_test\n",
    "})\n",
    "sample.to_csv(f'data/out/p{assignmentID}.csv', index=False)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame({\n",
    "    'Code': X_edits_code,\n",
    "    'Progress_score': progress_score(X_edits),\n",
    "    'Correctness_score': clf.predict_proba(X_edits)[:,1]\n",
    "})\n",
    "sample.to_csv(f'data/out/p{assignmentID}-edits.csv', index=False)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f321f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def print_rule(clf, index):\n",
    "    estimator = clf.estimators_[index]\n",
    "#     name = feature_names[estimator.tree_.feature[0]]\n",
    "#     thresh = estimator.tree_.threshold[0]\n",
    "#     estimator_samples = clf.estimators_samples_[index]\n",
    "#     children = estimator.apply(X_resampled[estimator_samples])\n",
    "#     perc_child_1 = np.mean(y_resampled[estimator_samples][children == 1])\n",
    "#     perc_child_2 = np.mean(y_resampled[estimator_samples][children == 2])\n",
    "#     pred_child_1 = perc_child_1 > 0.5\n",
    "#     pred_child_2 = perc_child_2 > 0.5\n",
    "#     if pred_child_1 and pred_child_2:\n",
    "#         print(f\"Degenerate rule: always {pred_child_1}\")\n",
    "#         return\n",
    "#     if pred_child_1:\n",
    "#         print (f\"If {name} < {thresh}, True\")\n",
    "#     else:\n",
    "#         print (f\"If {name} > {thresh}, True\")\n",
    "    plot_tree(estimator)\n",
    "    \n",
    "print_rule(clf, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[feature_names[est.tree_.feature[0]] for est in clf.estimators_]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3fee5d4f3b5ecb199b852979c68e41625787e5c54294d622957919c3dfbf6cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
