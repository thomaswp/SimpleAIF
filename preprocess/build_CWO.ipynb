{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da628",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../server')\n",
    "\n",
    "import progress\n",
    "from progsnap import ProgSnap2Dataset\n",
    "from progsnap import PS2\n",
    "from progsnap import EventType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f5b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_columns = [EventType.Submit, EventType.RunProgram, 'Project.Submit']\n",
    "problem_id = 13\n",
    "problem_id_column = PS2.ProblemID\n",
    "code_column = PS2.Code\n",
    "data_folder = \"data/cwo-f19/\"\n",
    "data_out_folder = \"../server/data/CWO/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ProgSnap2Dataset(data_folder)\n",
    "main_table = data.get_main_table()\n",
    "main_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_states = data.get_code_states_table()\n",
    "code_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc3a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should probably also be submit... but this is ok too\n",
    "submissions = main_table[main_table[PS2.EventType].isin(submit_columns)]\n",
    "submissions.groupby(problem_id_column).Score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f04b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_submissions = submissions[submissions[problem_id_column] == problem_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a047853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_code = pd.merge(assignment_submissions, code_states, on=PS2.CodeStateID)[[problem_id_column, PS2.Score, code_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assignment_code.copy()\n",
    "df[\"Code\"] = df[code_column]\n",
    "df[\"Correct\"] = df[\"Score\"] == 1\n",
    "df = df[~df[\"Code\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa27c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "X = df.Code\n",
    "y = df.Correct\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_code, X_test_code, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#vectorizer = TfidfVectorizer(lowercase=False, token_pattern=\"[\\w]+|[^\\s]|[ ]{4}\")\n",
    "vectorizer = CountVectorizer(lowercase=False, token_pattern=\"[\\w]+|[^\\s]|[ ]{4}\", ngram_range=(1,3))\n",
    "vectorizer.fit(X_train_code)\n",
    "X_train = vectorizer.transform(X_train_code)\n",
    "X_test = vectorizer.transform(X_test_code)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "np.mean(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baebeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier, cv\n",
    "\n",
    "# clf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                        # n_estimators=20, random_state=0).fit(X_resampled, y_resampled)\n",
    "\n",
    "# clf = SVC().fit(X_resampled, y_resampled)\n",
    "\n",
    "clf = XGBClassifier().fit(X_resampled, y_resampled)\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('scale', StandardScaler(with_mean=False)),\n",
    "#     ('logistic', LogisticRegressionCV(cv=5, random_state=1234, max_iter=1000))\n",
    "# ]).fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Training performance (without oversampling)\n",
    "pred_train = clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "confusion_matrix(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201b0c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(data_out_folder):\n",
    "   os.makedirs(data_out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd637aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', clf)])\n",
    "\n",
    "with open(f'{data_out_folder}model-{problem_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_code[y_train].reset_index().Code.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e046ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Of all correct submissions, plot the distribution of proportion of submissions where each feature appears at least once\n",
    "sns.kdeplot((X_train[y_train].toarray() > 0).mean(axis=0))\n",
    "\n",
    "# We want to see a bimodal distribution here, with most features either appearing\n",
    "# << 0.5 or ~1.0. If not, we may need to adjust the parameter on the ProgressEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import progress\n",
    "\n",
    "\n",
    "estimator = progress.ProgressEstimator().fit(X_train[y_train])\n",
    "\n",
    "# Plot the progress of all submissions, regardless of their correctness\n",
    "# We expect to see most near 1, a none near 0\n",
    "sns.histplot(estimator.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9032893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', estimator)])\n",
    "\n",
    "with open(f'{data_out_folder}/progress-{problem_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_csids = main_table[main_table[problem_id_column] == problem_id][PS2.CodeStateID].unique()\n",
    "all_code = code_states[code_states[PS2.CodeStateID].isin(unique_csids)][code_column]\n",
    "print(all_code.iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_edits_code = all_edits.Contents.str.decode('UTF-8').apply(strip_comments)\n",
    "X_edits = vectorizer.transform(all_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0643d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87372e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.min_score)\n",
    "print(estimator.max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_edits_code = all_code.Contents.str.decode('UTF-8').apply(strip_comments)\n",
    "sns.histplot(estimator.predict_proba(X_edits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3fee5d4f3b5ecb199b852979c68e41625787e5c54294d622957919c3dfbf6cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
