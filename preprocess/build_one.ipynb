{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221dcf5f",
   "metadata": {},
   "source": [
    "### Imports, Config and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da628",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from shared.progress import ProgressEstimator\n",
    "from shared.progsnap import ProgSnap2Dataset, PS2, EventType\n",
    "from shared.database import CSVDataProvider, SQLiteDataProvider\n",
    "from shared.data import SQLiteLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9053c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from configs import config_PCRS, config_iSnap, config_CWO\n",
    "\n",
    "# Assign variable directly so Pylance doesn't get upset\n",
    "submit_columns = None\n",
    "test_problem_id = None\n",
    "problem_id_column = None\n",
    "code_column = None\n",
    "data_folder = None\n",
    "database = None\n",
    "\n",
    "# Chose the config you want to use\n",
    "locals().update(config_PCRS)\n",
    "\n",
    "# Set the problem_id to something specific, or use the default test problem\n",
    "problem_id = test_problem_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List problem IDs, in case you want to change to a different one\n",
    "dataset = ProgSnap2Dataset(CSVDataProvider(data_folder))\n",
    "dataset.get_main_table()[problem_id_column].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0b8c5",
   "metadata": {},
   "source": [
    "### Build the Models and Save to the DB\n",
    "\n",
    "Load a ProgSnap2 dataset for one problem, build the progress and classifier models, and save them to the server's SQLite database for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d96bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.preprocess import SimpleAIFBuilder\n",
    "\n",
    "builder = SimpleAIFBuilder(\n",
    "    problem_id,\n",
    "    code_column=code_column,\n",
    "    problem_id_column=problem_id_column\n",
    ")\n",
    "builder.build(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.data import SQLiteLogger\n",
    "\n",
    "logger = SQLiteLogger(database)\n",
    "logger.create_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d363c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_model = builder.get_trained_progress_model()\n",
    "classifier = builder.get_trained_classifier()\n",
    "correct_count = int(builder.X_train[builder.y_train].unique().size)\n",
    "logger.set_models(problem_id, progress_model, classifier, correct_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3502647",
   "metadata": {},
   "source": [
    "### Further explore the model's outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of attempts that got this problem correct\n",
    "builder.mean_scores[problem_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 50 n-gram features for this problem\n",
    "builder.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bfc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classifier model's training performance\n",
    "report, cm = builder.get_training_report()\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5226949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classifier model's CV testing performance\n",
    "report, cm = builder.get_cv_report()\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example of a correct submission for this problem\n",
    "print(builder.get_correct_submissions()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e046ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of all correct submissions, plot the distribution of the number of times each feature appears at least once\n",
    "sns.kdeplot((builder.get_vectorized_submissions()[builder.y_train].toarray() > 0).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757820d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The starter code for this problem\n",
    "print(builder.get_starter_code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164408fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the progress of all submissions, regardless of their correctness\n",
    "sns.histplot(builder.get_trained_progress_model().predict_proba(builder.X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa8523",
   "metadata": {},
   "source": [
    "### Quickly add the Dataset to the SQLite Database\n",
    "This prepopulates the server's SQLite database with all student data for the current problem, in case we want to update the models dynamically as the server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.clear_table(\"MainTable\")\n",
    "logger.clear_table(\"CodeStates\")\n",
    "logger.clear_table(\"Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15faa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_table = SimpleAIFBuilder.get_submissions_table(dataset)\n",
    "submissions_table = submissions_table[submissions_table[problem_id_column] == problem_id]\n",
    "code_table = dataset.get_code_states_table()\n",
    "submissions_table = pd.merge(submissions_table, code_table, on=PS2.CodeStateID)\n",
    "submissions_table.rename(columns={code_column: \"CodeState\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22305710",
   "metadata": {},
   "source": [
    "We can add the data to the SQLite database directly using the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00469ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in submissions_table.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    del row_dict[\"CodeStateID\"]\n",
    "    del row_dict[\"Order\"]\n",
    "    event_type = row[PS2.EventType]\n",
    "    if event_type not in [\"Submit\", \"FileEdit\", \"Run.Program\"]:\n",
    "        continue\n",
    "    logger.log_event(event_type, row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72363c27",
   "metadata": {},
   "source": [
    "### Test populating a Dataset using the SimpleAIF Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70269b",
   "metadata": {},
   "source": [
    "We can also add the data to the SQLite database using the server endpoint (if it's running) to test that functionality. This code is redundant with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f790b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 1\n",
    "limit = 100000\n",
    "\n",
    "for index, row in submissions_table.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    del row_dict[\"CodeStateID\"]\n",
    "    del row_dict[\"Order\"]\n",
    "    del row_dict[\"ParentEventID\"]\n",
    "    event_type = row[PS2.EventType]\n",
    "    if event_type not in [\"Submit\", \"FileEdit\", \"Run.Program\"]:\n",
    "        print(event_type)\n",
    "        continue\n",
    "    # Remove nan values from the dict\n",
    "    row_dict = {k: v for k, v in row_dict.items() if not pd.isnull(v)}\n",
    "    row_dict[\"ShouldLog\"] = True\n",
    "    url = f\"http://127.0.0.1:5000/{row[PS2.EventType]}/\"\n",
    "    x = requests.post(url, json = row_dict)\n",
    "\n",
    "    limit -= 1\n",
    "    if limit == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5712a",
   "metadata": {},
   "source": [
    "We can also test uploading starter code via the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa26ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10000\n",
    "\n",
    "starter_code = dataset.load_link_table(\"Problem\")\n",
    "for index, row in starter_code.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    url = f\"http://127.0.0.1:5000/X-SetStarterCode/\"\n",
    "    x = requests.post(url, json = row_dict)\n",
    "\n",
    "    limit -= 1\n",
    "    if limit == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1dbab5",
   "metadata": {},
   "source": [
    "### Test building the models directly from the SQLite database\n",
    "If the server updates dynamically, it will log new submissions to the SQLite database and regularly rebuild the models. This code tests that functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sql = ProgSnap2Dataset(SQLiteDataProvider(database))\n",
    "\n",
    "builder_sql = SimpleAIFBuilder(\n",
    "    str(problem_id),\n",
    "    code_column=code_column,\n",
    "    problem_id_column=problem_id_column\n",
    ")\n",
    "builder_sql.build(dataset_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ec7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, cm = builder_sql.get_cv_report()\n",
    "print(report)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3207b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleAIFBuilder.get_submissions_table(dataset_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sql.get_code_states_table()[\"CodeStateID\"] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d872f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_sql.mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.get_starter_code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3fee5d4f3b5ecb199b852979c68e41625787e5c54294d622957919c3dfbf6cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
